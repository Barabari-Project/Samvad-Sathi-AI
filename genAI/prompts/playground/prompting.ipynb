{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6cbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164d57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt: str, system:str = None,model: str = \"gpt-4o-mini\", temperature: float = 0.7) -> str:\n",
    "    try:\n",
    "        messages = []\n",
    "        if system:\n",
    "            messages = [{\"role\":\"system\",\"content\":system}]\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error in call_llm func: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ef13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_dict(text: str):\n",
    "    try:\n",
    "        start = min(\n",
    "            (text.index('{') if '{' in text else float('inf')),\n",
    "            (text.index('[') if '[' in text else float('inf'))\n",
    "        )\n",
    "        end = max(\n",
    "            (text.rindex('}') + 1 if '}' in text else -1),\n",
    "            (text.rindex(']') + 1 if ']' in text else -1)\n",
    "        )\n",
    "        json_str = text[start:end]\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(text)\n",
    "        print(json_str)\n",
    "        raise ValueError(f\"Invalid JSON found: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd311489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_dict(text: str):\n",
    "    try:\n",
    "        start = min(\n",
    "            (text.index('{') if '{' in text else float('inf')),\n",
    "            (text.index('[') if '[' in text else float('inf'))\n",
    "        )\n",
    "        end = max(\n",
    "            (text.rindex('}') + 1 if '}' in text else -1),\n",
    "            (text.rindex(']') + 1 if ']' in text else -1)\n",
    "        )\n",
    "        json_str = text[start:end]\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(text)\n",
    "        print(json_str)\n",
    "        raise ValueError(f\"Invalid JSON found: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a13a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_resume = '''\n",
    "{\n",
    "  \"experience\": [\n",
    "    {\n",
    "      \"company\": \"The Barabari Collective\",\n",
    "      \"position\": \"AI Engineer (Freelance)\",\n",
    "      \"duration\": \"June 2025 - Present\"\n",
    "    },\n",
    "    {\n",
    "      \"company\": \"GDSC DDU Chapter\",\n",
    "      \"position\": \"AI/ML Team Member\",\n",
    "      \"duration\": \"2023-2024\"\n",
    "    }\n",
    "  ],\n",
    "  \"certifications\": [\n",
    "    \"Advanced Learning Algorithms - DeepLearning.AI\",\n",
    "    \"Introduction to TensorFlow for AI, ML and DL - DeepLearning.AI\",\n",
    "    \"Supervised Machine Learning - Stanford University\"\n",
    "  ],\n",
    "  \"projects\": [\n",
    "    {\n",
    "      \"name\": \"ChatGPT 2\",\n",
    "      \"description\": \"Trained and implemented from scratch in Pytorch. Winner of Bhashathon 2025, won a cash prize of Rs. 50,000.\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": {\n",
    "    \"Languages\": [\n",
    "      \"Python\",\n",
    "      \"C++\",\n",
    "      \"JavaScript\"\n",
    "    ],\n",
    "    \"Libraries\": [\n",
    "      \"PyTorch\",\n",
    "      \"NumPy\",\n",
    "      \"Pandas\",\n",
    "      \"Matplotlib\",\n",
    "      \"FAISS\",\n",
    "      \"scikit-learn\"\n",
    "    ],\n",
    "    \"Frameworks\": [\n",
    "      \"Flask\",\n",
    "      \"FastAPI\",\n",
    "      \"Express.js\",\n",
    "      \"TensorFlow\"\n",
    "    ],\n",
    "    \"Tools & Technologies\": [\n",
    "      \"Git\",\n",
    "      \"AWS\",\n",
    "      \"Linux\",\n",
    "      \"SentencePiece\",\n",
    "      \"OpenAI\",\n",
    "      \"OpenAI-Agents\",\n",
    "      \"Deepgram\",\n",
    "      \"openSMILE\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c5af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mention ratios in catagories of questions - 60-20-10-10\n",
    "# add hints to each question\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "**ROLE**\n",
    "You are an expert interviewer with deep experience in hiring for the role of {Role}. Your task is to create highly tailored, insightful interview questions based on the candidate's resume, work history, skills, and years of experience.\n",
    "\n",
    "### INSTRUCTION\n",
    "1. **Question Generation**\n",
    "   - Create **15-20 questions** covering these categories, elaborate on questions to help the candidate understand the question better:\n",
    "     - **Technical**: Core DS concepts (ML, stats, coding)\n",
    "     - **Behavioral**: Soft skills, teamwork, problem-solving\n",
    "     - **Role-specific**: Job description alignment (e.g., NLP, MLOps)\n",
    "     - **Resume-specific**: Directly from resume content (projects, skills, gaps)\n",
    "   - **Label each question** with its category (e.g., `[Technical]`).\n",
    "\n",
    "2. **Difficulty Settings** (based on years of experience):\n",
    "   | **Experience** | **Easy** | **Medium** | **Hard** | **Distribution** |\n",
    "   |----------------|----------|------------|----------|-----------------------|\n",
    "   | **0-2 years** | Foundational concepts | Basic applications | Theoretical depth | 50% Easy, 30% Medium, 20% Hard |\n",
    "   | **2-5 years** | Applied scenarios | Optimization trade-offs | System design | 30% Easy, 40% Medium, 30% Hard |\n",
    "   | **5+ years** | Edge cases | Architecture decisions | Leadership/strategy | 20% Easy, 30% Medium, 50% Hard |\n",
    "\n",
    "   - **Difficulty Definitions**:\n",
    "     - **Easy**: Definitions, basic syntax, simple scenarios.\n",
    "     - **Medium**: Applied problem-solving, trade-off analysis.\n",
    "     - **Hard**: System design, optimization, failure mitigation.\n",
    "\n",
    "3. **Resume Integration**\n",
    "   - Extract **3 resume-specific questions** targeting:\n",
    "     - Projects listed\n",
    "     - Skills claimed (e.g., \"Python,\" \"Express\")\n",
    "     - Experience gaps/job hops\n",
    "\n",
    "4. **Output Format**\n",
    "   ```markdown\n",
    "   [Category] Difficulty: [Easy/Medium/Hard]\n",
    "   Question: [Your question here]\n",
    "   ```\n",
    "   - **Do NOT** add explanations or numbering.\n",
    "   \n",
    "### EXAMPLE\n",
    "{examples}\n",
    "\n",
    "### CONTEXT (Knowledge Grounding / Syllabus)\n",
    "Questions must draw exclusively from these topics:\n",
    "{context}\n",
    "\n",
    "### TASK\n",
    "Generate questions for:\n",
    "- **Years of Experience**: {years_of_experience}\n",
    "- **Resume**: {user_resume}\n",
    "{job_description}\n",
    "\n",
    "**Output**: 15-20 questions following the format above.\n",
    "\n",
    "### KEY RULES\n",
    "1. **No open-ended decisions**: All questions MUST adhere to the syllabus and difficulty rules.\n",
    "2. **Resume fidelity**: Resume-specific questions must reference exact projects/skills.\n",
    "3. **Diversity**: Cover ≥2 topics per category (e.g., stats + ML for Technical).\n",
    "4. **Role alignment**: 40% of questions must map to the job description.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add examples of all difficulties\n",
    "# https://akanksha-paul.medium.com/interview-experience-for-applied-scientist-at-amazon-5ff5003375dd\n",
    "\n",
    "ML_examples = '''\n",
    "**Candidate**: 3 years of experience, resume includes \"CNN image classification project.\"\n",
    "```markdown\n",
    "[Technical] Difficulty: Medium\n",
    "Question: Explain how you'd mitigate overfitting in a CNN for image classification.\n",
    "\n",
    "[Behavioral] Difficulty: Easy\n",
    "Question: Describe a time you resolved a conflict in a cross-functional team.\n",
    "\n",
    "[Role-specific] Difficulty: Hard\n",
    "Question: Design a real-time fraud detection system for transactional data (assume 1M RPM).\n",
    "\n",
    "[Resume-specific] Difficulty: Medium\n",
    "Question: Your resume mentions a CNN project—what data augmentation techniques did you use and why?\n",
    "```\n",
    "'''\n",
    "\n",
    "ML_context = '''\n",
    "Questions must draw **exclusively** from these topics:\n",
    "\n",
    "### **Enhanced Technical Syllabus**  \n",
    "**1. Statistics & Probability**  \n",
    "- *Hypothesis Testing*: T-tests, Z-tests, ANOVA, p-values, Type I/II errors  \n",
    "- *Bayesian Inference*: Priors/posteriors, Bayes' theorem applications  \n",
    "- *Distributions*: Gaussian, Poisson, Binomial properties and use cases  \n",
    "- *A/B Testing*: Power analysis, sequential testing, covariate adjustment  \n",
    "\n",
    "**2. Machine Learning**  \n",
    "- *Supervised Learning*:  \n",
    "  - Algorithms: Linear/logistic regression, SVM, tree-based methods (RF, XGBoost)  \n",
    "  - Evaluation: ROC curves, precision-recall tradeoffs, cross-validation strategies  \n",
    "- *Unsupervised Learning*: K-means clustering, PCA, anomaly detection  \n",
    "- *Regularization*: L1/L2 penalties, dropout, early stopping  \n",
    "\n",
    "**3. Coding & Tools**  \n",
    "- *Python*:  \n",
    "  - Pandas (data wrangling, time-series manipulation)  \n",
    "  - Scikit-learn (pipeline construction, hyperparameter tuning)  \n",
    "- *SQL*: Window functions, query optimization, nested queries  \n",
    "- *Git*: Branching strategies, rebase vs. merge, CI/CD integration  \n",
    "- *Cloud Platforms*:  \n",
    "  - AWS (SageMaker, Redshift) / GCP (BigQuery, Vertex AI)  \n",
    "\n",
    "**4. Data Engineering**  \n",
    "- *ETL Pipelines*: Batch vs. stream processing (Airflow vs. Kafka)  \n",
    "- *Data Warehousing*: Star/snowflake schemas, slowly changing dimensions  \n",
    "- *Big Data Tools*: Spark (RDD/DataFrame API), Hadoop ecosystem  \n",
    "\n",
    "**5. Advanced Topics**  \n",
    "- *Deep Learning*:  \n",
    "  - CNNs (architectures like ResNet, transfer learning)  \n",
    "  - RNNs (LSTM/GRU, sequence-to-sequence models)  \n",
    "- *NLP*: Transformer architecture, fine-tuning BERT, attention mechanisms  \n",
    "- *MLOps*: Model monitoring, drift detection, feature stores  \n",
    "\n",
    "---\n",
    "\n",
    "### **Behavioral Syllabus**  \n",
    "**Core Framework**  \n",
    "- **STAR Method**: Structured storytelling (Situation, Task, Action, Result) with quantifiable outcomes  \n",
    "- **Prioritization**: Eisenhower matrix, ROI-based task triage, resource constraints  \n",
    "- **Ethical Dilemmas**: Data privacy (GDPR/CCPA), model bias mitigation, explainability tradeoffs  \n",
    "- **Stakeholder Communication**: Tailoring messages to executives vs. engineers, conflict resolution  \n",
    "\n",
    "**Integrated Amazon Leadership Principles**  \n",
    "1. **Earn Trust**:  \n",
    "   - *Focus*: Building psychological safety, admitting mistakes, delivering on commitments  \n",
    "   - *Sample Q*: \"Describe a time you received critical feedback. How did you rebuild trust?\"  \n",
    "\n",
    "2. **Are Right, A Lot**:  \n",
    "   - *Focus*: Data-driven decision-making, balancing intuition with evidence, handling ambiguous data  \n",
    "   - *Sample Q*: \"When did you advocate for a counterintuitive solution backed by data?\"  \n",
    "\n",
    "3. **Invent and Simplify**:  \n",
    "   - *Focus*: Creating scalable solutions, reducing technical debt, elegant problem-solving  \n",
    "   - *Sample Q*: \"Share an example where you turned a complex process into a simple solution.\"  \n",
    "\n",
    "### **Role-Specific Additions**  \n",
    "**NLP Specialist**  \n",
    "- *Must-Know*: Attention mechanisms, transformer variants (RoBERTa, T5), Hugging Face ecosystem  \n",
    "- *Tools*: spaCy, NLTK, BERTopic  \n",
    "\n",
    "**ML Engineer**  \n",
    "- *Must-Know*: Containerization (Docker), serverless deployment, model versioning (MLflow)  \n",
    "- *Tools*: Kubernetes, TF Serving, Prometheus for monitoring  \n",
    "\n",
    "**Analytics Lead**  \n",
    "- *Must-Know*: Causal inference (propensity scoring, DiD), cohort analysis, monetization metrics  \n",
    "- *Tools*: Optimizely, Mixpanel, Monte Carlo simulations  \n",
    "'''\n",
    "# be more explicit on syllabus\n",
    "\n",
    "# amazon leadership principles could be added in behavioral\n",
    "# Earn Trust\n",
    "# Are Right, A Lot\n",
    "# Invent and Simplify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "989f2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend_examples = '''\n",
    "##Example 1\n",
    "Candidate: 1 year of experience, resume includes \"Mobile-first PWA for local business.\"\n",
    "\n",
    "```markdown\n",
    "[Technical] Difficulty: Easy  \n",
    "Question: When would you use CSS Grid vs. Flexbox? Provide layout examples.  \n",
    "\n",
    "[Behavioral] Difficulty: Medium  \n",
    "Question: How would you handle disagreements with a designer about implementation feasibility?  \n",
    "\n",
    "[Role-specific] Difficulty: Medium  \n",
    "Question: Design a service worker caching strategy for a PWA with frequently updated product catalogs.  \n",
    "\n",
    "[Resume-specific] Difficulty: Hard  \n",
    "Question: Your PWA claims 40% faster TTI—what metrics did you track and how did you achieve this?\n",
    "```\n",
    "\n",
    "##Example 2\n",
    "Candidate: 6 years of experience, resume includes \"Micro-frontend architecture migration.\"\n",
    "\n",
    "```markdown\n",
    "[Technical] Difficulty: Hard  \n",
    "Question: Compare hydration strategies for SSR applications (e.g., React vs Qwik).  \n",
    "\n",
    "[Behavioral] Difficulty: Hard  \n",
    "Question: Describe a technical debt situation you inherited and how you drove systemic fixes.  \n",
    "\n",
    "[Role-specific] Difficulty: Medium  \n",
    "Question: How would you implement a design system to ensure consistency across micro-frontends?  \n",
    "\n",
    "[Resume-specific] Difficulty: Medium  \n",
    "Question: Your migration project mentions Webpack Module Federation—what were the biggest integration challenges?\n",
    "```\n",
    "'''\n",
    "\n",
    "frontend_context = \"\"\"\n",
    "#### **Technical Syllabus**  \n",
    "1. **Core Web Technologies**  \n",
    "   - HTML5 (semantic elements, accessibility), CSS3 (Flexbox/Grid, animations), JavaScript (ES6+, async/event loop)  \n",
    "   - DOM manipulation, browser APIs, Web Performance (Critical Rendering Path, Lighthouse)  \n",
    "\n",
    "2. **Frontend Frameworks & Libraries**  \n",
    "   - React (hooks, state management), Vue, Angular, Svelte  \n",
    "   - Component lifecycle, virtual DOM, SSR/SSG (Next.js, Nuxt)  \n",
    "\n",
    "3. **State Management & Data Handling**  \n",
    "   - Redux, Context API, React Query, GraphQL/Apollo  \n",
    "   - RESTful APIs, WebSockets, error handling  \n",
    "\n",
    "4. **Styling & Design Systems**  \n",
    "   - CSS-in-JS (Styled Components, Emotion), preprocessors (Sass)  \n",
    "   - Responsive design, cross-browser compatibility, UI/UX principles  \n",
    "\n",
    "5. **Tooling & Workflow**  \n",
    "   - Build tools (Webpack, Vite), testing (Jest, React Testing Library, Cypress)  \n",
    "   - CI/CD pipelines, package managers (npm/yarn), TypeScript  \n",
    "\n",
    "#### **Behavioral Syllabus**\n",
    "   - STAR method, prioritization, ethical dilemmas, stakeholder communication\n",
    "\n",
    "#### **Role-specific Syllabus**  \n",
    "   - **UX-Focused Frontend**: Component libraries, interaction design  \n",
    "   - **Performance Specialist**: Bundle optimization, Core Web Vitals  \n",
    "   - **Full-Stack Frontend**: API integration, BFF (Backend For Frontend) patterns  \n",
    "   - **Accessibility Engineer**: WCAG compliance, ARIA, assistive tech testing  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9dfb7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_examples = '''\n",
    "Candidate: 3 years backend experience, resume highlights \"Scaled payment API handling 5K RPM\"\n",
    "\n",
    "##Example 1\n",
    "```markdown\n",
    "[Technical] Difficulty: Medium  \n",
    "Question: How would you implement idempotency in a payment processing API?\n",
    "\n",
    "[Behavioral] Difficulty: Medium  \n",
    "Question: Tell me about a time you had to refactor critical code under tight deadlines. What trade-offs did you consider?\n",
    "\n",
    "[Role-specific] Difficulty: Hard  \n",
    "Question: Design a rate-limiting system for our API that supports 100K+ unique clients with dynamic throttling rules.\n",
    "\n",
    "[Resume-specific] Difficulty: Medium  \n",
    "Question: Your payment API handled 5K RPM - what strategies did you use for database connection pooling under load?\n",
    "```\n",
    "\n",
    "##Example 2\n",
    "Candidate: 1 year experience, resume includes \"Deployed serverless microservices on AWS\"\n",
    "\n",
    "```markdown\n",
    "[Technical] Difficulty: Easy  \n",
    "Question: Explain how you'd choose between SQS and Kafka for inter-service communication.\n",
    "\n",
    "[Behavioral] Difficulty: Easy  \n",
    "Question: Describe a technical challenge you faced during an internship and how you sought help.\n",
    "\n",
    "[Role-specific] Difficulty: Medium  \n",
    "Question: How would you design a file processing pipeline where uploads take >15 minutes? Consider cost and reliability.\n",
    "\n",
    "[Resume-specific] Difficulty: Medium  \n",
    "Question: For your serverless project, what monitoring metrics did you track and why?\n",
    "```\n",
    "'''\n",
    "\n",
    "\n",
    "backend_context = '''\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee999971",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'years_of_experience'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# - **Role**: \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ml_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mML_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mML_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mRole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData Science\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m frontend_prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(user_resume\u001b[38;5;241m=\u001b[39mml_resume,\n\u001b[1;32m      8\u001b[0m                                 years_of_experience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                 job_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m                                 Role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrontend Developer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m                                 )\n\u001b[1;32m     15\u001b[0m backend_prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(user_resume\u001b[38;5;241m=\u001b[39mml_resume,\n\u001b[1;32m     16\u001b[0m                                 years_of_experience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     17\u001b[0m                                 job_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                 Role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend Developer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m                                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'years_of_experience'"
     ]
    }
   ],
   "source": [
    "# - **Role**: \n",
    "ml_prompt = prompt_template.format(user_resume=ml_resume,\n",
    "                                years_of_experience=0,\n",
    "                                job_description=\"\",\n",
    "                                examples=ML_examples,\n",
    "                                context=ML_context,\n",
    "                                Role=\"Data Science\",\n",
    "                                )\n",
    "frontend_prompt = prompt_template.format(user_resume=ml_resume,\n",
    "                                years_of_experience=0,\n",
    "                                job_description=\"\",\n",
    "                                examples=frontend_examples,\n",
    "                                context=frontend_context,\n",
    "                                Role=\"Frontend Developer\",\n",
    "                                )\n",
    "\n",
    "backend_prompt = prompt_template.format(user_resume=ml_resume,\n",
    "                                years_of_experience=0,\n",
    "                                job_description=\"\",\n",
    "                                examples=backend_examples,\n",
    "                                context=backend_context,\n",
    "                                Role=\"backend Developer\",\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236c2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = call_llm(prompt=ml_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "486ecceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Technical] Difficulty: Easy\n",
      "Question: Can you explain the difference between a list and a dictionary in Python?\n",
      "\n",
      "[Technical] Difficulty: Medium\n",
      "Question: Describe a scenario where you would use L1 regularization over L2 regularization.\n",
      "\n",
      "[Technical] Difficulty: Hard\n",
      "Question: How would you approach designing an A/B test to evaluate a new feature for a mobile application?\n",
      "\n",
      "[Behavioral] Difficulty: Easy\n",
      "Question: Can you describe a time when you had to collaborate with a team to solve a technical challenge?\n",
      "\n",
      "[Behavioral] Difficulty: Medium\n",
      "Question: When you've disagreed with your team on the direction of a project, how did you handle the situation?\n",
      "\n",
      "[Role-specific] Difficulty: Medium\n",
      "Question: Given your use of PyTorch for the ChatGPT 2 project, can you describe how PyTorch compares to TensorFlow for NLP tasks?\n",
      "\n",
      "[Role-specific] Difficulty: Hard\n",
      "Question: How would you manage deployment and testing while developing AI models in a ML Engineer role? Specifically, discuss any CI/CD workflows you are familiar with.\n",
      "\n",
      "[Resume-specific] Difficulty: Easy\n",
      "Question: I see you've worked as an AI Engineer for The Barabari Collective, can you explain what the work involved and what technical skills you used in this role?\n",
      "\n",
      "[Resume-specific] Difficulty: Medium\n",
      "Question: Can you describe the challenges and methodologies adopted while developing the ChatGPT 2 model?\n",
      "\n",
      "[Resume-specific] Difficulty: Hard\n",
      "Question: You've stated that you're proficient with both PyTorch and TensorFlow on your resume. Can you discuss a time you had to decide between the two for a specific project at The Barabari Collective?\n",
      "\n",
      "[Role-specific] Difficulty: Easy\n",
      "Question: Given your completion of the \"Advanced Learning Algorithms\" certification course - could you describe the most significant learning gained and how you have utilized it in a project?\n",
      "\n",
      "[Role-specific] Difficulty: Medium\n",
      "Question: For your ChatGPT 2 project, how did you decide on the Architectural nuances, given the suite of NLP libraries available to you?\n",
      "\n",
      "[Behavioral] Difficulty: Easy\n",
      "Question: How do you prioritize your work when multiple tasks are assigned to you simultaneously?\n",
      "\n",
      "[Behavioral] Difficulty: Medium\n",
      "Question: Please tell me about a challenging technical problem that you encountered and how you resolved it?\n",
      "\n",
      "[Behavioral] Difficulty: Hard\n",
      "Question: Describe a situation where you had to consider the ethical implications of your AI solution in a real-world project.\n",
      "\n",
      "[Technical] Difficulty: Easy\n",
      "Question: What is the difference between a scatter plot and a line plot in Matplotlib?\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80a6b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitative Feedback:\n",
      "Words Per Minute (WPM): Your average pace: 108.1 WPM\n",
      "Benchmarking: Aim for 120-150 WPM in interviews\n",
      "\n",
      "Pace Range Classification:\n",
      "- Too Slow: Your pace was slow 25.2% of the time\n",
      "- Ideal: You spoke at ideal pace for 47.7% of the time\n",
      "- Too Fast: Your pace exceeded 170 WPM for 0.9% of the time\n",
      "\n",
      "Detailed Pace Segments:\n",
      "\n",
      "Too slow segments:\n",
      "- [00:02 - 00:04]: so um one\n",
      "- [00:05 - 00:06]: was like\n",
      "- [00:24 - 00:32]: all and um it had just wasn't working good so um we\n",
      "- [01:00 - 01:06]: you know what I mean and so um yeah so\n",
      "- [01:07 - 01:12]: the model itself was like tough it's\n",
      "- [01:21 - 01:22]: tha and\n",
      "- [01:28 - 01:33]: accumulation and stuff and processed data in\n",
      "\n",
      "Ideal segments:\n",
      "- [00:07 - 00:18]: ODIA language you know it had like way less data than others so model was like kind of struggling to learn it properly I'm\n",
      "- [00:19 - 00:23]: you know the loss was and all\n",
      "- [00:33 - 00:34]: we tried to\n",
      "- [00:35 - 00:37]: like fix that by making batches\n",
      "- [00:39 - 00:42]: like you know make sure each batch\n",
      "- [00:46 - 00:50]: so like even if ODIA ka data kam tha\n",
      "- [00:51 - 00:53]: still came in training I\n",
      "- [00:54 - 01:00]: it helped kind of but not fully cause data hi kam tha\n",
      "- [01:18 - 01:21]: memory ka kaafi issue de raha tha\n",
      "- [01:23 - 01:24]: be limited tha\n",
      "- [01:25 - 01:27]: so um we did\n",
      "- [01:34 - 01:38]: like um small parts so it doesn't\n",
      "- [01:41 - 01:51]: like haan it was kind of difficult but I mean we did jugaad and somehow trained it and yeah I\n",
      "\n",
      "Too fast segments:\n",
      "- [01:51 - 01:57]: I learned a lot but still like next time we can do better you know what I mean\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = {\n",
    "  \"feedback\": \"Quantitative Feedback:\\nWords Per Minute (WPM): Your average pace: 108.1 WPM\\nBenchmarking: Aim for 120-150 WPM in interviews\\n\\nPace Range Classification:\\n- Too Slow: Your pace was slow 25.2% of the time\\n- Ideal: You spoke at ideal pace for 47.7% of the time\\n- Too Fast: Your pace exceeded 170 WPM for 0.9% of the time\\n\\nDetailed Pace Segments:\\n\\nToo slow segments:\\n- [00:02 - 00:04]: so um one\\n- [00:05 - 00:06]: was like\\n- [00:24 - 00:32]: all and um it had just wasn't working good so um we\\n- [01:00 - 01:06]: you know what I mean and so um yeah so\\n- [01:07 - 01:12]: the model itself was like tough it's\\n- [01:21 - 01:22]: tha and\\n- [01:28 - 01:33]: accumulation and stuff and processed data in\\n\\nIdeal segments:\\n- [00:07 - 00:18]: ODIA language you know it had like way less data than others so model was like kind of struggling to learn it properly I'm\\n- [00:19 - 00:23]: you know the loss was and all\\n- [00:33 - 00:34]: we tried to\\n- [00:35 - 00:37]: like fix that by making batches\\n- [00:39 - 00:42]: like you know make sure each batch\\n- [00:46 - 00:50]: so like even if ODIA ka data kam tha\\n- [00:51 - 00:53]: still came in training I\\n- [00:54 - 01:00]: it helped kind of but not fully cause data hi kam tha\\n- [01:18 - 01:21]: memory ka kaafi issue de raha tha\\n- [01:23 - 01:24]: be limited tha\\n- [01:25 - 01:27]: so um we did\\n- [01:34 - 01:38]: like um small parts so it doesn't\\n- [01:41 - 01:51]: like haan it was kind of difficult but I mean we did jugaad and somehow trained it and yeah I\\n\\nToo fast segments:\\n- [01:51 - 01:57]: I learned a lot but still like next time we can do better you know what I mean\\n\"\n",
    "}\n",
    "print(a[\"feedback\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abac6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samvadSathiAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
