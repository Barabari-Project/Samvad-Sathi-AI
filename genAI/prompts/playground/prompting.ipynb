{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6a03bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Interview Performance Report\n",
      "\n",
      "## Candidate Overview\n",
      "This report evaluates the interview performance of the candidate based on an aggregated analysis of their knowledge, communication skills, and speech fluency metrics. The following sections will outline the candidate's strengths, areas for improvement, and actionable steps for future development.\n",
      "\n",
      "---\n",
      "\n",
      "### ðŸ§¾ Final Summary\n",
      "\n",
      "The candidate demonstrated some fundamental knowledge of the subject matter, particularly in the areas of relevance but struggled with clarity and technical depth. Their communication skills were notably affected by structural issues and linguistic choices, impacting their overall fluency. Improvements in both knowledge depth and communication effectiveness are essential for future interactions.\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… Strengths\n",
      "\n",
      "**Knowledge-Related:**\n",
      "- The candidate exhibited a solid understanding of challenges relevant to the subject, showing capability in identifying key issues.\n",
      "- Relevant terminology was utilized effectively, indicating familiarity with the terms commonly used in the field.\n",
      "- The strongest knowledge attribute demonstrated was the candidate's ability to recognize problems and articulate the relevance of their solutions.\n",
      "\n",
      "**Speech Fluency-Related:**\n",
      "- The candidate maintained a consistent pacing, with a majority of their speech remaining on topic, which is a positive communication trait.\n",
      "- Despite the presence of filler words, the candidate's overall communication patterns occasionally provided valuable insights.\n",
      "- Vocabulary, while basic, still included terms appropriate for the context, showing a foundational level of subject knowledge.\n",
      "\n",
      "---\n",
      "\n",
      "### âŒ Areas for Improvement\n",
      "\n",
      "**Knowledge-Related:**\n",
      "- The candidate displayed conceptual gaps, particularly in providing detailed explanations and outcomes relevant to their knowledge base.\n",
      "- Specific examples and deeper elaboration in discussions could significantly enhance the depth of their responses and improve their credibility.\n",
      "- Inconsistencies in explanations led to some confusing moments, indicating a need for more structured knowledge consolidation.\n",
      "\n",
      "**Speech Fluency-Related:**\n",
      "- Frequent use of filler words and phrases disrupted the objective clarity of the candidateâ€™s responses, affecting the overall professionalism of their speech.\n",
      "- Grammar and syntax issues were prevalent, with multiple instances of awkward sentence constructions that impeded fluency and coherence.\n",
      "- There were significant structural issues, including abrupt transitions that detracted from the narrative flow and thematic cohesion.\n",
      "- The average speech rate was below the target range, signaling a need for improved pacing during conversations to meet standard expectations.\n",
      "\n",
      "---\n",
      "\n",
      "### ðŸŽ¯ Actionable Steps\n",
      "\n",
      "**For Knowledge Development:**\n",
      "1. **Targeted Reading:** Recommend the following resources for deeper understanding:\n",
      "   - Industry-related articles and case studies that provide practical examples and evidence.\n",
      "   - Technical manuals or standards relevant to their field of work.\n",
      "   \n",
      "2. **Discussion Group:** Join or form a study group where the candidate can discuss technical topics with peers, enhancing their depth of understanding through dialogue and peer feedback.\n",
      "\n",
      "3. **Reflective Writing Exercises:** Encourage the candidate to write brief summaries of technical outcomes from their experiences, focusing on clarity and depth.\n",
      "\n",
      "---\n",
      "\n",
      "**For Speech & Structure:**\n",
      "1. **Filler Word Reduction Practice:** Have the candidate record themselves speaking about a topic for two minutes, focusing on reducing filler word usage, followed by self-analysis.\n",
      "\n",
      "2. **Grammar and Syntax Drills:** Introduce targeted exercises focusing on common grammatical mistakes and sentence structure improvement, such as online tutorials or language apps.\n",
      "\n",
      "3. **Pacing Improvement Strategies:** Recommend regular practices, such as timed speech exercises, to raise their average words per minute (WPM) to meet the target zone. They could also try reading out loud to a friend or mentor for feedback on pacing.\n",
      "\n",
      "By focusing on these specific, actionable steps, the candidate will be able to enhance their knowledge depth and spoken communication skills significantly. Regular assessment and practice in these areas will contribute to a more effective engagement in future professional interactions.\n"
     ]
    }
   ],
   "source": [
    "a = {\n",
    "  \"report\": \"# Interview Performance Report\\n\\n## Candidate Overview\\nThis report evaluates the interview performance of the candidate based on an aggregated analysis of their knowledge, communication skills, and speech fluency metrics. The following sections will outline the candidate's strengths, areas for improvement, and actionable steps for future development.\\n\\n---\\n\\n### ðŸ§¾ Final Summary\\n\\nThe candidate demonstrated some fundamental knowledge of the subject matter, particularly in the areas of relevance but struggled with clarity and technical depth. Their communication skills were notably affected by structural issues and linguistic choices, impacting their overall fluency. Improvements in both knowledge depth and communication effectiveness are essential for future interactions.\\n\\n---\\n\\n### âœ… Strengths\\n\\n**Knowledge-Related:**\\n- The candidate exhibited a solid understanding of challenges relevant to the subject, showing capability in identifying key issues.\\n- Relevant terminology was utilized effectively, indicating familiarity with the terms commonly used in the field.\\n- The strongest knowledge attribute demonstrated was the candidate's ability to recognize problems and articulate the relevance of their solutions.\\n\\n**Speech Fluency-Related:**\\n- The candidate maintained a consistent pacing, with a majority of their speech remaining on topic, which is a positive communication trait.\\n- Despite the presence of filler words, the candidate's overall communication patterns occasionally provided valuable insights.\\n- Vocabulary, while basic, still included terms appropriate for the context, showing a foundational level of subject knowledge.\\n\\n---\\n\\n### âŒ Areas for Improvement\\n\\n**Knowledge-Related:**\\n- The candidate displayed conceptual gaps, particularly in providing detailed explanations and outcomes relevant to their knowledge base.\\n- Specific examples and deeper elaboration in discussions could significantly enhance the depth of their responses and improve their credibility.\\n- Inconsistencies in explanations led to some confusing moments, indicating a need for more structured knowledge consolidation.\\n\\n**Speech Fluency-Related:**\\n- Frequent use of filler words and phrases disrupted the objective clarity of the candidateâ€™s responses, affecting the overall professionalism of their speech.\\n- Grammar and syntax issues were prevalent, with multiple instances of awkward sentence constructions that impeded fluency and coherence.\\n- There were significant structural issues, including abrupt transitions that detracted from the narrative flow and thematic cohesion.\\n- The average speech rate was below the target range, signaling a need for improved pacing during conversations to meet standard expectations.\\n\\n---\\n\\n### ðŸŽ¯ Actionable Steps\\n\\n**For Knowledge Development:**\\n1. **Targeted Reading:** Recommend the following resources for deeper understanding:\\n   - Industry-related articles and case studies that provide practical examples and evidence.\\n   - Technical manuals or standards relevant to their field of work.\\n   \\n2. **Discussion Group:** Join or form a study group where the candidate can discuss technical topics with peers, enhancing their depth of understanding through dialogue and peer feedback.\\n\\n3. **Reflective Writing Exercises:** Encourage the candidate to write brief summaries of technical outcomes from their experiences, focusing on clarity and depth.\\n\\n---\\n\\n**For Speech & Structure:**\\n1. **Filler Word Reduction Practice:** Have the candidate record themselves speaking about a topic for two minutes, focusing on reducing filler word usage, followed by self-analysis.\\n\\n2. **Grammar and Syntax Drills:** Introduce targeted exercises focusing on common grammatical mistakes and sentence structure improvement, such as online tutorials or language apps.\\n\\n3. **Pacing Improvement Strategies:** Recommend regular practices, such as timed speech exercises, to raise their average words per minute (WPM) to meet the target zone. They could also try reading out loud to a friend or mentor for feedback on pacing.\\n\\nBy focusing on these specific, actionable steps, the candidate will be able to enhance their knowledge depth and spoken communication skills significantly. Regular assessment and practice in these areas will contribute to a more effective engagement in future professional interactions.\"\n",
    "}\n",
    "print(a['report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61af596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Final Summary\n",
      "\n",
      "#### âœ… Strengths\n",
      "\n",
      "**Knowledge-Related:**\n",
      "- **Technical Understanding Areas:** \n",
      "  - The candidate demonstrated a solid understanding of the challenges associated with implementing multilingual models, specifically highlighting issues with underrepresented languages such as ODIA.\n",
      "  - There was an ability to recognize the impact of data volume on model performance, which is crucial for project success.\n",
      "- **Precise Terminology Usage:** \n",
      "  - Terms like \"gradient accumulation\" showcased some technical vocabulary relevant to machine learning hardware strategies.\n",
      "\n",
      "**Speech Fluency-Related:**\n",
      "- **Effective Communication Patterns:** \n",
      "  - The candidate was able to articulate the identification of technical challenges during the project.\n",
      "  - Pacing was generally steady, with brief moments of clear expression amid more rushed speech.\n",
      "- **Positive Aspects of Pacing/Structure:**\n",
      "  - Selected sections displayed coherent thought processes despite some clarity issues and presented a basic logical structure.\n",
      "\n",
      "#### âŒ Areas for Improvement\n",
      "\n",
      "**Knowledge-Related:**\n",
      "- **Critical Conceptual Gaps:**\n",
      "  - There was a lack of precision in describing technical details related to model training, such as the specific implications of the data volume on model performance.\n",
      "  - Generic references to attempts at resolution without providing specific metrics or clear outcomes missed opportunities to showcase depth.\n",
      "- **Examples Needing Deeper Evidence:**\n",
      "  - Statements about overcoming challenges were broad, lacking concrete examples or detailed quantitative results from the analysis.\n",
      "\n",
      "**Speech Fluency-Related:**\n",
      "- **Frequent Filler Words/Patterns:** \n",
      "  - Phrases such as \"you know what I mean,\" \"um,\" and \"like\" detracted from the clarity and professional tone of responses.\n",
      "- **Critical Grammar/Syntax Challenges:**\n",
      "  - The use of informal speech patterns and grammatical inaccuracies weakened the overall fluency, such as \"it had, just wasn't working good.\"\n",
      "- **Pacing Distribution Issues:**\n",
      "  - A significant percentage of rushed speech (22.6%) indicated a need for improved pacing, possibly leading to unclear communication.\n",
      "\n",
      "### ðŸŽ¯ Actionable Steps\n",
      "\n",
      "**For Knowledge Development:**\n",
      "1. **Study Recommendations:**\n",
      "   - Engage with resources focused on advanced machine learning topics, particularly in multilingual applications. Suggested readings include â€œDeep Learning for Natural Language Processingâ€ by Palash Goyal.\n",
      "   - Review case studies on successful implementation of language models to understand best practices and outcomes.\n",
      "\n",
      "2. **Practical Exercise Types:**\n",
      "   - Conduct hands-on projects simulating multilingual model training, focusing on data collection and preprocessing techniques. Measure model performance across different metrics.\n",
      "   - Create a journal documenting challenges encountered during project work, utilizing specific data to illustrate the learning process.\n",
      "\n",
      "**For Speech & Structure:**\n",
      "1. **Targeted Fluency Exercises:**\n",
      "   - Practice mock interviews with a peer or mentor, focusing specifically on minimizing filler words. Recording responses to analyze fluency can be beneficial.\n",
      "   - Engage in public speaking forums or workshops to enhance confidence in structured communication.\n",
      "\n",
      "2. **Specific Grammar/Structure Drills:**\n",
      "   - Dedicate time to exercises focused on creating complex sentences with correct grammar. Online platforms like Grammarly or language learning apps can assist.\n",
      "   - Create outlines for responses before speaking to build a clear organizational structure and logical flow.\n",
      "\n",
      "3. **Pacing Improvement Strategies:**\n",
      "   - Implement techniques such as deliberate pauses and breath control to manage speech speed. Practicing speaking along with a metronome set to a target rhythm can help.\n",
      "   - Record practice sessions to monitor pacing, and gradually increase the speaking speed while maintaining clarity.\n"
     ]
    }
   ],
   "source": [
    "b = {\n",
    "  \"report\": \"### Final Summary\\n\\n#### âœ… Strengths\\n\\n**Knowledge-Related:**\\n- **Technical Understanding Areas:** \\n  - The candidate demonstrated a solid understanding of the challenges associated with implementing multilingual models, specifically highlighting issues with underrepresented languages such as ODIA.\\n  - There was an ability to recognize the impact of data volume on model performance, which is crucial for project success.\\n- **Precise Terminology Usage:** \\n  - Terms like \\\"gradient accumulation\\\" showcased some technical vocabulary relevant to machine learning hardware strategies.\\n\\n**Speech Fluency-Related:**\\n- **Effective Communication Patterns:** \\n  - The candidate was able to articulate the identification of technical challenges during the project.\\n  - Pacing was generally steady, with brief moments of clear expression amid more rushed speech.\\n- **Positive Aspects of Pacing/Structure:**\\n  - Selected sections displayed coherent thought processes despite some clarity issues and presented a basic logical structure.\\n\\n#### âŒ Areas for Improvement\\n\\n**Knowledge-Related:**\\n- **Critical Conceptual Gaps:**\\n  - There was a lack of precision in describing technical details related to model training, such as the specific implications of the data volume on model performance.\\n  - Generic references to attempts at resolution without providing specific metrics or clear outcomes missed opportunities to showcase depth.\\n- **Examples Needing Deeper Evidence:**\\n  - Statements about overcoming challenges were broad, lacking concrete examples or detailed quantitative results from the analysis.\\n\\n**Speech Fluency-Related:**\\n- **Frequent Filler Words/Patterns:** \\n  - Phrases such as \\\"you know what I mean,\\\" \\\"um,\\\" and \\\"like\\\" detracted from the clarity and professional tone of responses.\\n- **Critical Grammar/Syntax Challenges:**\\n  - The use of informal speech patterns and grammatical inaccuracies weakened the overall fluency, such as \\\"it had, just wasn't working good.\\\"\\n- **Pacing Distribution Issues:**\\n  - A significant percentage of rushed speech (22.6%) indicated a need for improved pacing, possibly leading to unclear communication.\\n\\n### ðŸŽ¯ Actionable Steps\\n\\n**For Knowledge Development:**\\n1. **Study Recommendations:**\\n   - Engage with resources focused on advanced machine learning topics, particularly in multilingual applications. Suggested readings include â€œDeep Learning for Natural Language Processingâ€ by Palash Goyal.\\n   - Review case studies on successful implementation of language models to understand best practices and outcomes.\\n\\n2. **Practical Exercise Types:**\\n   - Conduct hands-on projects simulating multilingual model training, focusing on data collection and preprocessing techniques. Measure model performance across different metrics.\\n   - Create a journal documenting challenges encountered during project work, utilizing specific data to illustrate the learning process.\\n\\n**For Speech & Structure:**\\n1. **Targeted Fluency Exercises:**\\n   - Practice mock interviews with a peer or mentor, focusing specifically on minimizing filler words. Recording responses to analyze fluency can be beneficial.\\n   - Engage in public speaking forums or workshops to enhance confidence in structured communication.\\n\\n2. **Specific Grammar/Structure Drills:**\\n   - Dedicate time to exercises focused on creating complex sentences with correct grammar. Online platforms like Grammarly or language learning apps can assist.\\n   - Create outlines for responses before speaking to build a clear organizational structure and logical flow.\\n\\n3. **Pacing Improvement Strategies:**\\n   - Implement techniques such as deliberate pauses and breath control to manage speech speed. Practicing speaking along with a metronome set to a target rhythm can help.\\n   - Record practice sessions to monitor pacing, and gradually increase the speaking speed while maintaining clarity.\"\n",
    "}\n",
    "print(b['report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c33e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ðŸ§¾ Final Summary (with Actionable Steps)\n",
      "\n",
      "The candidate showcased both strengths and areas for growth during the interview. While they demonstrated some understanding of relevant technologies and an ability to address project-related challenges, the precision in technical details and clarity in communication were lacking. Improvement in these areas, alongside more structured communication, will enhance overall performance.\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… Strengths\n",
      "\n",
      "**Knowledge-Related:**\n",
      "- The candidate displayed technical understanding by accurately identifying techniques such as watermarking and scaling.\n",
      "- Demonstrated awareness of key challenges in project implementation, addressing issues related to dashboard approach and synchronization directly.\n",
      "- Relevant terminology was used, with specific examples such as mentioning Kafka and Flink.\n",
      "\n",
      "**Speech Fluency-Related:**\n",
      "- Maintained a consistent narrative structure, albeit disrupted. The attempt to follow a chronological order of explanation shows an understanding of logical progression.\n",
      "- The speech maintained a moderate pace (103.4 WPM), which provided ample time for processing information despite being below the target range.\n",
      "\n",
      "---\n",
      "\n",
      "### âŒ Areas for Improvement\n",
      "\n",
      "**Knowledge-Related:**\n",
      "- Conceptual gaps were noted where consumer group purposes were mischaracterized, and implementation trade-offs lacked depth.\n",
      "- The responses were often generic, missing deeper examples and quantitative details, such as metrics of performance improvement when using Kafka.\n",
      "- Inconsistent explanations were evident in sentences like \"Memory issues also came up though, cause servers were like, overloaded.\"\n",
      "\n",
      "**Speech Fluency-Related:**\n",
      "- Frequent filler word usage, as highlighted in phrases like \"like,\" \"you know,\" and \"kind of,\" detracted from message clarity.\n",
      "- There were noticeable grammar/syntax challenges, such as inconsistent tense and awkward phrases: \"it had, just wasn't working good.\"\n",
      "- Structural issues arose from tangential thoughts and topic shifts, impacting the coherence of explanations.\n",
      "\n",
      "---\n",
      "\n",
      "### ðŸŽ¯ Actionable Steps\n",
      "\n",
      "**For Knowledge Development:**\n",
      "1. **Deepen Technical Understanding:** Study resources on consumer group mechanics and implementation trade-offs to address conceptual gaps. Suggested reading includes comprehensive Kafka tutorials and distribution scaling strategies.\n",
      "2. **Quantitative Metrics Practice:** Engage in exercises that involve the evaluation and presentation of technical solutions using specific metrics and frameworks, such as case studies where performance metrics are critical.\n",
      "3. **Detail Oriented Learning:** Focus on implementing small-scale projects that underscore technical precision, involving performance tracking and comparative analysis between technologies like Kafka and Flink.\n",
      "\n",
      "**For Speech & Structure:**\n",
      "1. **Reduce Filler Words:** Practice speaking with short presentations on technical topics, consciously avoiding filler words as noted in \"like,\" \"you know what I mean.\" Recording and reviewing speeches will aid in identifying and minimizing filler usage.\n",
      "2. **Grammar & Structure Drills:** Engage in writing exercises based on common grammatical errors observed, such as using correct tenses and punctuation in structured paragraphs. Working with complex sentence structures will aid fluency.\n",
      "3. **Pacing Improvement Strategies:** Gradually increase speaking speed through timed reading exercises. Listening to and imitating podcasts or speeches that model the target WPM can provide a benchmark for speech rate improvement.\n"
     ]
    }
   ],
   "source": [
    "c = {\n",
    "  \"report\": \"### ðŸ§¾ Final Summary (with Actionable Steps)\\n\\nThe candidate showcased both strengths and areas for growth during the interview. While they demonstrated some understanding of relevant technologies and an ability to address project-related challenges, the precision in technical details and clarity in communication were lacking. Improvement in these areas, alongside more structured communication, will enhance overall performance.\\n\\n---\\n\\n### âœ… Strengths\\n\\n**Knowledge-Related:**\\n- The candidate displayed technical understanding by accurately identifying techniques such as watermarking and scaling.\\n- Demonstrated awareness of key challenges in project implementation, addressing issues related to dashboard approach and synchronization directly.\\n- Relevant terminology was used, with specific examples such as mentioning Kafka and Flink.\\n\\n**Speech Fluency-Related:**\\n- Maintained a consistent narrative structure, albeit disrupted. The attempt to follow a chronological order of explanation shows an understanding of logical progression.\\n- The speech maintained a moderate pace (103.4 WPM), which provided ample time for processing information despite being below the target range.\\n\\n---\\n\\n### âŒ Areas for Improvement\\n\\n**Knowledge-Related:**\\n- Conceptual gaps were noted where consumer group purposes were mischaracterized, and implementation trade-offs lacked depth.\\n- The responses were often generic, missing deeper examples and quantitative details, such as metrics of performance improvement when using Kafka.\\n- Inconsistent explanations were evident in sentences like \\\"Memory issues also came up though, cause servers were like, overloaded.\\\"\\n\\n**Speech Fluency-Related:**\\n- Frequent filler word usage, as highlighted in phrases like \\\"like,\\\" \\\"you know,\\\" and \\\"kind of,\\\" detracted from message clarity.\\n- There were noticeable grammar/syntax challenges, such as inconsistent tense and awkward phrases: \\\"it had, just wasn't working good.\\\"\\n- Structural issues arose from tangential thoughts and topic shifts, impacting the coherence of explanations.\\n\\n---\\n\\n### ðŸŽ¯ Actionable Steps\\n\\n**For Knowledge Development:**\\n1. **Deepen Technical Understanding:** Study resources on consumer group mechanics and implementation trade-offs to address conceptual gaps. Suggested reading includes comprehensive Kafka tutorials and distribution scaling strategies.\\n2. **Quantitative Metrics Practice:** Engage in exercises that involve the evaluation and presentation of technical solutions using specific metrics and frameworks, such as case studies where performance metrics are critical.\\n3. **Detail Oriented Learning:** Focus on implementing small-scale projects that underscore technical precision, involving performance tracking and comparative analysis between technologies like Kafka and Flink.\\n\\n**For Speech & Structure:**\\n1. **Reduce Filler Words:** Practice speaking with short presentations on technical topics, consciously avoiding filler words as noted in \\\"like,\\\" \\\"you know what I mean.\\\" Recording and reviewing speeches will aid in identifying and minimizing filler usage.\\n2. **Grammar & Structure Drills:** Engage in writing exercises based on common grammatical errors observed, such as using correct tenses and punctuation in structured paragraphs. Working with complex sentence structures will aid fluency.\\n3. **Pacing Improvement Strategies:** Gradually increase speaking speed through timed reading exercises. Listening to and imitating podcasts or speeches that model the target WPM can provide a benchmark for speech rate improvement.\"\n",
    "}\n",
    "\n",
    "print(c[\"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6cbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164d57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt: str, system:str = None,model: str = \"gpt-4o-mini\", temperature: float = 0.7) -> str:\n",
    "    try:\n",
    "        messages = []\n",
    "        if system:\n",
    "            messages = [{\"role\":\"system\",\"content\":system}]\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error in call_llm func: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ef13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_dict(text: str):\n",
    "    try:\n",
    "        start = min(\n",
    "            (text.index('{') if '{' in text else float('inf')),\n",
    "            (text.index('[') if '[' in text else float('inf'))\n",
    "        )\n",
    "        end = max(\n",
    "            (text.rindex('}') + 1 if '}' in text else -1),\n",
    "            (text.rindex(']') + 1 if ']' in text else -1)\n",
    "        )\n",
    "        json_str = text[start:end]\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(text)\n",
    "        print(json_str)\n",
    "        raise ValueError(f\"Invalid JSON found: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd311489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_dict(text: str):\n",
    "    try:\n",
    "        start = min(\n",
    "            (text.index('{') if '{' in text else float('inf')),\n",
    "            (text.index('[') if '[' in text else float('inf'))\n",
    "        )\n",
    "        end = max(\n",
    "            (text.rindex('}') + 1 if '}' in text else -1),\n",
    "            (text.rindex(']') + 1 if ']' in text else -1)\n",
    "        )\n",
    "        json_str = text[start:end]\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(text)\n",
    "        print(json_str)\n",
    "        raise ValueError(f\"Invalid JSON found: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a13a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_resume = '''\n",
    "{\n",
    "  \"experience\": [\n",
    "    {\n",
    "      \"company\": \"The Barabari Collective\",\n",
    "      \"position\": \"AI Engineer (Freelance)\",\n",
    "      \"duration\": \"June 2025 - Present\"\n",
    "    },\n",
    "    {\n",
    "      \"company\": \"GDSC DDU Chapter\",\n",
    "      \"position\": \"AI/ML Team Member\",\n",
    "      \"duration\": \"2023-2024\"\n",
    "    }\n",
    "  ],\n",
    "  \"certifications\": [\n",
    "    \"Advanced Learning Algorithms - DeepLearning.AI\",\n",
    "    \"Introduction to TensorFlow for AI, ML and DL - DeepLearning.AI\",\n",
    "    \"Supervised Machine Learning - Stanford University\"\n",
    "  ],\n",
    "  \"projects\": [\n",
    "    {\n",
    "      \"name\": \"ChatGPT 2\",\n",
    "      \"description\": \"Trained and implemented from scratch in Pytorch. Winner of Bhashathon 2025, won a cash prize of Rs. 50,000.\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": {\n",
    "    \"Languages\": [\n",
    "      \"Python\",\n",
    "      \"C++\",\n",
    "      \"JavaScript\"\n",
    "    ],\n",
    "    \"Libraries\": [\n",
    "      \"PyTorch\",\n",
    "      \"NumPy\",\n",
    "      \"Pandas\",\n",
    "      \"Matplotlib\",\n",
    "      \"FAISS\",\n",
    "      \"scikit-learn\"\n",
    "    ],\n",
    "    \"Frameworks\": [\n",
    "      \"Flask\",\n",
    "      \"FastAPI\",\n",
    "      \"Express.js\",\n",
    "      \"TensorFlow\"\n",
    "    ],\n",
    "    \"Tools & Technologies\": [\n",
    "      \"Git\",\n",
    "      \"AWS\",\n",
    "      \"Linux\",\n",
    "      \"SentencePiece\",\n",
    "      \"OpenAI\",\n",
    "      \"OpenAI-Agents\",\n",
    "      \"Deepgram\",\n",
    "      \"openSMILE\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c5af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mention ratios in catagories of questions - 60-20-10-10\n",
    "# add hints to each question\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "**ROLE**\n",
    "You are an expert interviewer with deep experience in hiring for the role of {Role}. Your task is to create highly tailored, insightful interview questions based on the candidate's resume, work history, skills, and years of experience.\n",
    "\n",
    "### INSTRUCTION\n",
    "1. **Question Generation**\n",
    "   - Create **15-20 questions** covering these categories, elaborate on questions to help the candidate understand the question better:\n",
    "     - **Technical**: Core DS concepts (ML, stats, coding)\n",
    "     - **Behavioral**: Soft skills, teamwork, problem-solving\n",
    "     - **Role-specific**: Job description alignment (e.g., NLP, MLOps)\n",
    "     - **Resume-specific**: Directly from resume content (projects, skills, gaps)\n",
    "   - **Label each question** with its category (e.g., `[Technical]`).\n",
    "\n",
    "2. **Difficulty Settings** (based on years of experience):\n",
    "   | **Experience** | **Easy** | **Medium** | **Hard** | **Distribution** |\n",
    "   |----------------|----------|------------|----------|-----------------------|\n",
    "   | **0-2 years** | Foundational concepts | Basic applications | Theoretical depth | 50% Easy, 30% Medium, 20% Hard |\n",
    "   | **2-5 years** | Applied scenarios | Optimization trade-offs | System design | 30% Easy, 40% Medium, 30% Hard |\n",
    "   | **5+ years** | Edge cases | Architecture decisions | Leadership/strategy | 20% Easy, 30% Medium, 50% Hard |\n",
    "\n",
    "   - **Difficulty Definitions**:\n",
    "     - **Easy**: Definitions, basic syntax, simple scenarios.\n",
    "     - **Medium**: Applied problem-solving, trade-off analysis.\n",
    "     - **Hard**: System design, optimization, failure mitigation.\n",
    "\n",
    "3. **Resume Integration**\n",
    "   - Extract **3 resume-specific questions** targeting:\n",
    "     - Projects listed\n",
    "     - Skills claimed (e.g., \"Python,\" \"Express\")\n",
    "     - Experience gaps/job hops\n",
    "\n",
    "4. **Output Format**\n",
    "   ```markdown\n",
    "   [Category] Difficulty: [Easy/Medium/Hard]\n",
    "   Question: [Your question here]\n",
    "   ```\n",
    "   - **Do NOT** add explanations or numbering.\n",
    "   \n",
    "### EXAMPLE\n",
    "{examples}\n",
    "\n",
    "### CONTEXT (Knowledge Grounding / Syllabus)\n",
    "Questions must draw exclusively from these topics:\n",
    "{context}\n",
    "\n",
    "### TASK\n",
    "Generate questions for:\n",
    "- **Years of Experience**: {years_of_experience}\n",
    "- **Resume**: {user_resume}\n",
    "{job_description}\n",
    "\n",
    "**Output**: 15-20 questions following the format above.\n",
    "\n",
    "### KEY RULES\n",
    "1. **No open-ended decisions**: All questions MUST adhere to the syllabus and difficulty rules.\n",
    "2. **Resume fidelity**: Resume-specific questions must reference exact projects/skills.\n",
    "3. **Diversity**: Cover â‰¥2 topics per category (e.g., stats + ML for Technical).\n",
    "4. **Role alignment**: 40% of questions must map to the job description.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add examples of all difficulties\n",
    "# https://akanksha-paul.medium.com/interview-experience-for-applied-scientist-at-amazon-5ff5003375dd\n",
    "\n",
    "ML_examples = '''\n",
    "**Candidate**: 3 years of experience, resume includes \"CNN image classification project.\"\n",
    "```markdown\n",
    "[Technical] Difficulty: Medium\n",
    "Question: Explain how you'd mitigate overfitting in a CNN for image classification.\n",
    "\n",
    "[Behavioral] Difficulty: Easy\n",
    "Question: Describe a time you resolved a conflict in a cross-functional team.\n",
    "\n",
    "[Role-specific] Difficulty: Hard\n",
    "Question: Design a real-time fraud detection system for transactional data (assume 1M RPM).\n",
    "\n",
    "[Resume-specific] Difficulty: Medium\n",
    "Question: Your resume mentions a CNN projectâ€”what data augmentation techniques did you use and why?\n",
    "```\n",
    "'''\n",
    "\n",
    "ML_context = '''\n",
    "Questions must draw **exclusively** from these topics:\n",
    "\n",
    "### **Enhanced Technical Syllabus**  \n",
    "**1. Statistics & Probability**  \n",
    "- *Hypothesis Testing*: T-tests, Z-tests, ANOVA, p-values, Type I/II errors  \n",
    "- *Bayesian Inference*: Priors/posteriors, Bayes' theorem applications  \n",
    "- *Distributions*: Gaussian, Poisson, Binomial properties and use cases  \n",
    "- *A/B Testing*: Power analysis, sequential testing, covariate adjustment  \n",
    "\n",
    "**2. Machine Learning**  \n",
    "- *Supervised Learning*:  \n",
    "  - Algorithms: Linear/logistic regression, SVM, tree-based methods (RF, XGBoost)  \n",
    "  - Evaluation: ROC curves, precision-recall tradeoffs, cross-validation strategies  \n",
    "- *Unsupervised Learning*: K-means clustering, PCA, anomaly detection  \n",
    "- *Regularization*: L1/L2 penalties, dropout, early stopping  \n",
    "\n",
    "**3. Coding & Tools**  \n",
    "- *Python*:  \n",
    "  - Pandas (data wrangling, time-series manipulation)  \n",
    "  - Scikit-learn (pipeline construction, hyperparameter tuning)  \n",
    "- *SQL*: Window functions, query optimization, nested queries  \n",
    "- *Git*: Branching strategies, rebase vs. merge, CI/CD integration  \n",
    "- *Cloud Platforms*:  \n",
    "  - AWS (SageMaker, Redshift) / GCP (BigQuery, Vertex AI)  \n",
    "\n",
    "**4. Data Engineering**  \n",
    "- *ETL Pipelines*: Batch vs. stream processing (Airflow vs. Kafka)  \n",
    "- *Data Warehousing*: Star/snowflake schemas, slowly changing dimensions  \n",
    "- *Big Data Tools*: Spark (RDD/DataFrame API), Hadoop ecosystem  \n",
    "\n",
    "**5. Advanced Topics**  \n",
    "- *Deep Learning*:  \n",
    "  - CNNs (architectures like ResNet, transfer learning)  \n",
    "  - RNNs (LSTM/GRU, sequence-to-sequence models)  \n",
    "- *NLP*: Transformer architecture, fine-tuning BERT, attention mechanisms  \n",
    "- *MLOps*: Model monitoring, drift detection, feature stores  \n",
    "\n",
    "---\n",
    "\n",
    "### **Behavioral Syllabus**  \n",
    "**Core Framework**  \n",
    "- **STAR Method**: Structured storytelling (Situation, Task, Action, Result) with quantifiable outcomes  \n",
    "- **Prioritization**: Eisenhower matrix, ROI-based task triage, resource constraints  \n",
    "- **Ethical Dilemmas**: Data privacy (GDPR/CCPA), model bias mitigation, explainability tradeoffs  \n",
    "- **Stakeholder Communication**: Tailoring messages to executives vs. engineers, conflict resolution  \n",
    "\n",
    "**Integrated Amazon Leadership Principles**  \n",
    "1. **Earn Trust**:  \n",
    "   - *Focus*: Building psychological safety, admitting mistakes, delivering on commitments  \n",
    "   - *Sample Q*: \"Describe a time you received critical feedback. How did you rebuild trust?\"  \n",
    "\n",
    "2. **Are Right, A Lot**:  \n",
    "   - *Focus*: Data-driven decision-making, balancing intuition with evidence, handling ambiguous data  \n",
    "   - *Sample Q*: \"When did you advocate for a counterintuitive solution backed by data?\"  \n",
    "\n",
    "3. **Invent and Simplify**:  \n",
    "   - *Focus*: Creating scalable solutions, reducing technical debt, elegant problem-solving  \n",
    "   - *Sample Q*: \"Share an example where you turned a complex process into a simple solution.\"  \n",
    "\n",
    "### **Role-Specific Additions**  \n",
    "**NLP Specialist**  \n",
    "- *Must-Know*: Attention mechanisms, transformer variants (RoBERTa, T5), Hugging Face ecosystem  \n",
    "- *Tools*: spaCy, NLTK, BERTopic  \n",
    "\n",
    "**ML Engineer**  \n",
    "- *Must-Know*: Containerization (Docker), serverless deployment, model versioning (MLflow)  \n",
    "- *Tools*: Kubernetes, TF Serving, Prometheus for monitoring  \n",
    "\n",
    "**Analytics Lead**  \n",
    "- *Must-Know*: Causal inference (propensity scoring, DiD), cohort analysis, monetization metrics  \n",
    "- *Tools*: Optimizely, Mixpanel, Monte Carlo simulations  \n",
    "'''\n",
    "# be more explicit on syllabus\n",
    "\n",
    "# amazon leadership principles could be added in behavioral\n",
    "# Earn Trust\n",
    "# Are Right, A Lot\n",
    "# Invent and Simplify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "989f2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend_examples = '''\n",
    "##Example 1\n",
    "Candidate: 1 year of experience, resume includes \"Mobile-first PWA for local business.\"\n",
    "\n",
    "```markdown\n",
    "[Technical] Difficulty: Easy  \n",
    "Question: When would you use CSS Grid vs. Flexbox? Provide layout examples.  \n",
    "\n",
    "[Behavioral] Difficulty: Medium  \n",
    "Question: How would you handle disagreements with a designer about implementation feasibility?  \n",
    "\n",
    "[Role-specific] Difficulty: Medium  \n",
    "Question: Design a service worker caching strategy for a PWA with frequently updated product catalogs.  \n",
    "\n",
    "[Resume-specific] Difficulty: Hard  \n",
    "Question: Your PWA claims 40% faster TTIâ€”what metrics did you track and how did you achieve this?\n",
    "```\n",
    "\n",
    "##Example 2\n",
    "Candidate: 6 years of experience, resume includes \"Micro-frontend architecture migration.\"\n",
    "\n",
    "```markdown\n",
    "[Technical] Difficulty: Hard  \n",
    "Question: Compare hydration strategies for SSR applications (e.g., React vs Qwik).  \n",
    "\n",
    "[Behavioral] Difficulty: Hard  \n",
    "Question: Describe a technical debt situation you inherited and how you drove systemic fixes.  \n",
    "\n",
    "[Role-specific] Difficulty: Medium  \n",
    "Question: How would you implement a design system to ensure consistency across micro-frontends?  \n",
    "\n",
    "[Resume-specific] Difficulty: Medium  \n",
    "Question: Your migration project mentions Webpack Module Federationâ€”what were the biggest integration challenges?\n",
    "```\n",
    "'''\n",
    "\n",
    "frontend_context = \"\"\"\n",
    "#### **Technical Syllabus**  \n",
    "1. **Core Web Technologies**  \n",
    "   - HTML5 (semantic elements, accessibility), CSS3 (Flexbox/Grid, animations), JavaScript (ES6+, async/event loop)  \n",
    "   - DOM manipulation, browser APIs, Web Performance (Critical Rendering Path, Lighthouse)  \n",
    "\n",
    "2. **Frontend Frameworks & Libraries**  \n",
    "   - React (hooks, state management), Vue, Angular, Svelte  \n",
    "   - Component lifecycle, virtual DOM, SSR/SSG (Next.js, Nuxt)  \n",
    "\n",
    "3. **State Management & Data Handling**  \n",
    "   - Redux, Context API, React Query, GraphQL/Apollo  \n",
    "   - RESTful APIs, WebSockets, error handling  \n",
    "\n",
    "4. **Styling & Design Systems**  \n",
    "   - CSS-in-JS (Styled Components, Emotion), preprocessors (Sass)  \n",
    "   - Responsive design, cross-browser compatibility, UI/UX principles  \n",
    "\n",
    "5. **Tooling & Workflow**  \n",
    "   - Build tools (Webpack, Vite), testing (Jest, React Testing Library, Cypress)  \n",
    "   - CI/CD pipelines, package managers (npm/yarn), TypeScript  \n",
    "\n",
    "#### **Behavioral Syllabus**\n",
    "   - STAR method, prioritization, ethical dilemmas, stakeholder communication\n",
    "\n",
    "#### **Role-specific Syllabus**  \n",
    "   - **UX-Focused Frontend**: Component libraries, interaction design  \n",
    "   - **Performance Specialist**: Bundle optimization, Core Web Vitals  \n",
    "   - **Full-Stack Frontend**: API integration, BFF (Backend For Frontend) patterns  \n",
    "   - **Accessibility Engineer**: WCAG compliance, ARIA, assistive tech testing  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9dfb7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_examples = '''\n",
    "Candidate: 3 years backend experience, resume highlights \"Scaled payment API handling 5K RPM\"\n",
    "\n",
    "##Example 1\n",
    "```markdown\n",
    "[Technical] Difficulty: Medium  \n",
    "Question: How would you implement idempotency in a payment processing API?\n",
    "\n",
    "[Behavioral] Difficulty: Medium  \n",
    "Question: Tell me about a time you had to refactor critical code under tight deadlines. What trade-offs did you consider?\n",
    "\n",
    "[Role-specific] Difficulty: Hard  \n",
    "Question: Design a rate-limiting system for our API that supports 100K+ unique clients with dynamic throttling rules.\n",
    "\n",
    "[Resume-specific] Difficulty: Medium  \n",
    "Question: Your payment API handled 5K RPM - what strategies did you use for database connection pooling under load?\n",
    "```\n",
    "\n",
    "##Example 2\n",
    "Candidate: 1 year experience, resume includes \"Deployed serverless microservices on AWS\"\n",
    "\n",
    "```markdown\n",
    "[Technical] Difficulty: Easy  \n",
    "Question: Explain how you'd choose between SQS and Kafka for inter-service communication.\n",
    "\n",
    "[Behavioral] Difficulty: Easy  \n",
    "Question: Describe a technical challenge you faced during an internship and how you sought help.\n",
    "\n",
    "[Role-specific] Difficulty: Medium  \n",
    "Question: How would you design a file processing pipeline where uploads take >15 minutes? Consider cost and reliability.\n",
    "\n",
    "[Resume-specific] Difficulty: Medium  \n",
    "Question: For your serverless project, what monitoring metrics did you track and why?\n",
    "```\n",
    "'''\n",
    "\n",
    "\n",
    "backend_context = '''\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee999971",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'years_of_experience'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# - **Role**: \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ml_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mML_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mML_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mRole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData Science\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m frontend_prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(user_resume\u001b[38;5;241m=\u001b[39mml_resume,\n\u001b[1;32m      8\u001b[0m                                 years_of_experience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                 job_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m                                 Role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrontend Developer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m                                 )\n\u001b[1;32m     15\u001b[0m backend_prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(user_resume\u001b[38;5;241m=\u001b[39mml_resume,\n\u001b[1;32m     16\u001b[0m                                 years_of_experience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     17\u001b[0m                                 job_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                 Role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend Developer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m                                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'years_of_experience'"
     ]
    }
   ],
   "source": [
    "# - **Role**: \n",
    "ml_prompt = prompt_template.format(user_resume=ml_resume,\n",
    "                                years_of_experience=0,\n",
    "                                job_description=\"\",\n",
    "                                examples=ML_examples,\n",
    "                                context=ML_context,\n",
    "                                Role=\"Data Science\",\n",
    "                                )\n",
    "frontend_prompt = prompt_template.format(user_resume=ml_resume,\n",
    "                                years_of_experience=0,\n",
    "                                job_description=\"\",\n",
    "                                examples=frontend_examples,\n",
    "                                context=frontend_context,\n",
    "                                Role=\"Frontend Developer\",\n",
    "                                )\n",
    "\n",
    "backend_prompt = prompt_template.format(user_resume=ml_resume,\n",
    "                                years_of_experience=0,\n",
    "                                job_description=\"\",\n",
    "                                examples=backend_examples,\n",
    "                                context=backend_context,\n",
    "                                Role=\"backend Developer\",\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236c2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = call_llm(prompt=ml_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "486ecceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Technical] Difficulty: Easy\n",
      "Question: Can you explain the difference between a list and a dictionary in Python?\n",
      "\n",
      "[Technical] Difficulty: Medium\n",
      "Question: Describe a scenario where you would use L1 regularization over L2 regularization.\n",
      "\n",
      "[Technical] Difficulty: Hard\n",
      "Question: How would you approach designing an A/B test to evaluate a new feature for a mobile application?\n",
      "\n",
      "[Behavioral] Difficulty: Easy\n",
      "Question: Can you describe a time when you had to collaborate with a team to solve a technical challenge?\n",
      "\n",
      "[Behavioral] Difficulty: Medium\n",
      "Question: When you've disagreed with your team on the direction of a project, how did you handle the situation?\n",
      "\n",
      "[Role-specific] Difficulty: Medium\n",
      "Question: Given your use of PyTorch for the ChatGPT 2 project, can you describe how PyTorch compares to TensorFlow for NLP tasks?\n",
      "\n",
      "[Role-specific] Difficulty: Hard\n",
      "Question: How would you manage deployment and testing while developing AI models in a ML Engineer role? Specifically, discuss any CI/CD workflows you are familiar with.\n",
      "\n",
      "[Resume-specific] Difficulty: Easy\n",
      "Question: I see you've worked as an AI Engineer for The Barabari Collective, can you explain what the work involved and what technical skills you used in this role?\n",
      "\n",
      "[Resume-specific] Difficulty: Medium\n",
      "Question: Can you describe the challenges and methodologies adopted while developing the ChatGPT 2 model?\n",
      "\n",
      "[Resume-specific] Difficulty: Hard\n",
      "Question: You've stated that you're proficient with both PyTorch and TensorFlow on your resume. Can you discuss a time you had to decide between the two for a specific project at The Barabari Collective?\n",
      "\n",
      "[Role-specific] Difficulty: Easy\n",
      "Question: Given your completion of the \"Advanced Learning Algorithms\" certification course - could you describe the most significant learning gained and how you have utilized it in a project?\n",
      "\n",
      "[Role-specific] Difficulty: Medium\n",
      "Question: For your ChatGPT 2 project, how did you decide on the Architectural nuances, given the suite of NLP libraries available to you?\n",
      "\n",
      "[Behavioral] Difficulty: Easy\n",
      "Question: How do you prioritize your work when multiple tasks are assigned to you simultaneously?\n",
      "\n",
      "[Behavioral] Difficulty: Medium\n",
      "Question: Please tell me about a challenging technical problem that you encountered and how you resolved it?\n",
      "\n",
      "[Behavioral] Difficulty: Hard\n",
      "Question: Describe a situation where you had to consider the ethical implications of your AI solution in a real-world project.\n",
      "\n",
      "[Technical] Difficulty: Easy\n",
      "Question: What is the difference between a scatter plot and a line plot in Matplotlib?\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80a6b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitative Feedback:\n",
      "Words Per Minute (WPM): Your average pace: 108.1 WPM\n",
      "Benchmarking: Aim for 120-150 WPM in interviews\n",
      "\n",
      "Pace Range Classification:\n",
      "- Too Slow: Your pace was slow 25.2% of the time\n",
      "- Ideal: You spoke at ideal pace for 47.7% of the time\n",
      "- Too Fast: Your pace exceeded 170 WPM for 0.9% of the time\n",
      "\n",
      "Detailed Pace Segments:\n",
      "\n",
      "Too slow segments:\n",
      "- [00:02 - 00:04]: so um one\n",
      "- [00:05 - 00:06]: was like\n",
      "- [00:24 - 00:32]: all and um it had just wasn't working good so um we\n",
      "- [01:00 - 01:06]: you know what I mean and so um yeah so\n",
      "- [01:07 - 01:12]: the model itself was like tough it's\n",
      "- [01:21 - 01:22]: tha and\n",
      "- [01:28 - 01:33]: accumulation and stuff and processed data in\n",
      "\n",
      "Ideal segments:\n",
      "- [00:07 - 00:18]: ODIA language you know it had like way less data than others so model was like kind of struggling to learn it properly I'm\n",
      "- [00:19 - 00:23]: you know the loss was and all\n",
      "- [00:33 - 00:34]: we tried to\n",
      "- [00:35 - 00:37]: like fix that by making batches\n",
      "- [00:39 - 00:42]: like you know make sure each batch\n",
      "- [00:46 - 00:50]: so like even if ODIA ka data kam tha\n",
      "- [00:51 - 00:53]: still came in training I\n",
      "- [00:54 - 01:00]: it helped kind of but not fully cause data hi kam tha\n",
      "- [01:18 - 01:21]: memory ka kaafi issue de raha tha\n",
      "- [01:23 - 01:24]: be limited tha\n",
      "- [01:25 - 01:27]: so um we did\n",
      "- [01:34 - 01:38]: like um small parts so it doesn't\n",
      "- [01:41 - 01:51]: like haan it was kind of difficult but I mean we did jugaad and somehow trained it and yeah I\n",
      "\n",
      "Too fast segments:\n",
      "- [01:51 - 01:57]: I learned a lot but still like next time we can do better you know what I mean\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = {\n",
    "  \"feedback\": \"Quantitative Feedback:\\nWords Per Minute (WPM): Your average pace: 108.1 WPM\\nBenchmarking: Aim for 120-150 WPM in interviews\\n\\nPace Range Classification:\\n- Too Slow: Your pace was slow 25.2% of the time\\n- Ideal: You spoke at ideal pace for 47.7% of the time\\n- Too Fast: Your pace exceeded 170 WPM for 0.9% of the time\\n\\nDetailed Pace Segments:\\n\\nToo slow segments:\\n- [00:02 - 00:04]: so um one\\n- [00:05 - 00:06]: was like\\n- [00:24 - 00:32]: all and um it had just wasn't working good so um we\\n- [01:00 - 01:06]: you know what I mean and so um yeah so\\n- [01:07 - 01:12]: the model itself was like tough it's\\n- [01:21 - 01:22]: tha and\\n- [01:28 - 01:33]: accumulation and stuff and processed data in\\n\\nIdeal segments:\\n- [00:07 - 00:18]: ODIA language you know it had like way less data than others so model was like kind of struggling to learn it properly I'm\\n- [00:19 - 00:23]: you know the loss was and all\\n- [00:33 - 00:34]: we tried to\\n- [00:35 - 00:37]: like fix that by making batches\\n- [00:39 - 00:42]: like you know make sure each batch\\n- [00:46 - 00:50]: so like even if ODIA ka data kam tha\\n- [00:51 - 00:53]: still came in training I\\n- [00:54 - 01:00]: it helped kind of but not fully cause data hi kam tha\\n- [01:18 - 01:21]: memory ka kaafi issue de raha tha\\n- [01:23 - 01:24]: be limited tha\\n- [01:25 - 01:27]: so um we did\\n- [01:34 - 01:38]: like um small parts so it doesn't\\n- [01:41 - 01:51]: like haan it was kind of difficult but I mean we did jugaad and somehow trained it and yeah I\\n\\nToo fast segments:\\n- [01:51 - 01:57]: I learned a lot but still like next time we can do better you know what I mean\\n\"\n",
    "}\n",
    "print(a[\"feedback\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abac6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samvadSathiAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
